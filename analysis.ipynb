{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n# Retail Forecasting – Analysis & Plots\n\nThis notebook generates portfolio-ready visuals from your pipeline outputs.\n\n**Expected files (produced by your pipeline):**\n- `data/processed/features.parquet`\n- `data/reports/predictions.csv`\n- (Optional) `data/reports/elasticity_by_sku.csv`\n\n**Outputs (images saved to `data/reports/`):**\n- `sales_trend.png`\n- `actual_vs_pred.png`\n- `total_series.png`\n- `error_hist.png`\n- `elasticity_scatter.png`\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nimport os\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nDATA = Path(\"data\")\nPROC = DATA / \"processed\"\nREPORTS = DATA / \"reports\"\nREPORTS.mkdir(parents=True, exist_ok=True)\n\nprint(\"Looking for:\", PROC / \"features.parquet\")\nprint(\"Looking for:\", REPORTS / \"predictions.csv\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# --- Sales Trend for a representative product-store pair ---\nfeatures_fp = PROC / \"features.parquet\"\nif features_fp.exists():\n    df = pd.read_parquet(features_fp)\n    # pick the top (product_id, store_id) by total units\n    if {\"product_id\",\"store_id\",\"date\",\"units\"}.issubset(df.columns):\n        top_pair = (df.groupby([\"product_id\",\"store_id\"])[\"units\"]\n                      .sum().sort_values(ascending=False).head(1).index[0])\n        sample = df[(df[\"product_id\"]==top_pair[0]) & (df[\"store_id\"]==top_pair[1])].copy()\n        sample = sample.sort_values(\"date\")\n        plt.figure(figsize=(10,4))\n        plt.plot(pd.to_datetime(sample[\"date\"]), sample[\"units\"], label=\"Units Sold\")\n        plt.title(f\"Sales Trend – product {top_pair[0]}, store {top_pair[1]}\")\n        plt.xlabel(\"Date\"); plt.ylabel(\"Units\"); plt.legend()\n        out = REPORTS / \"sales_trend.png\"\n        plt.savefig(out, bbox_inches=\"tight\", dpi=150)\n        plt.show()\n        print(\"Saved:\", out)\n    else:\n        print(\"features.parquet missing required columns.\")\nelse:\n    print(\"features.parquet not found. Run your pipeline up to feature engineering.\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# --- Actual vs Predicted scatter ---\npred_fp = REPORTS / \"predictions.csv\"\nif pred_fp.exists():\n    pred = pd.read_csv(pred_fp)\n    if {\"units\",\"pred_units\"}.issubset(pred.columns):\n        plt.figure(figsize=(6,6))\n        plt.scatter(pred[\"units\"], pred[\"pred_units\"], alpha=0.3)\n        lo = 0\n        hi = max(pred[\"units\"].max(), pred[\"pred_units\"].max())\n        plt.plot([lo, hi], [lo, hi], linestyle=\"--\")\n        plt.title(\"Actual vs Predicted Demand\")\n        plt.xlabel(\"Actual Units\"); plt.ylabel(\"Predicted Units\")\n        out = REPORTS / \"actual_vs_pred.png\"\n        plt.savefig(out, bbox_inches=\"tight\", dpi=150)\n        plt.show()\n        print(\"Saved:\", out)\n    else:\n        print(\"predictions.csv missing required columns.\")\nelse:\n    print(\"predictions.csv not found. Run training + scoring first.\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# --- Total Actual vs Predicted over time ---\npred_fp = REPORTS / \"predictions.csv\"\nif pred_fp.exists():\n    pred = pd.read_csv(pred_fp, parse_dates=[\"date\"])\n    if {\"date\",\"units\",\"pred_units\"}.issubset(pred.columns):\n        ts = pred.groupby(\"date\")[[\"units\",\"pred_units\"]].sum().sort_index()\n        ax = ts.plot(figsize=(10,4))\n        ax.set_title(\"Total Demand: Actual vs Predicted (daily)\")\n        ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Units\")\n        out = REPORTS / \"total_series.png\"\n        plt.tight_layout(); plt.savefig(out, bbox_inches=\"tight\", dpi=150)\n        plt.show()\n        print(\"Saved:\", out)\n    else:\n        print(\"predictions.csv missing date/units columns.\")\nelse:\n    print(\"predictions.csv not found.\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# --- Error distribution histogram ---\npred_fp = REPORTS / \"predictions.csv\"\nif pred_fp.exists():\n    pred = pd.read_csv(pred_fp)\n    if {\"units\",\"pred_units\"}.issubset(pred.columns):\n        pred = pred.copy()\n        pred[\"error\"] = pred[\"pred_units\"] - pred[\"units\"]\n        ax = pred[\"error\"].hist(bins=40, figsize=(8,4))\n        ax.set_title(\"Prediction Error Distribution (pred - actual)\")\n        ax.set_xlabel(\"Error\"); ax.set_ylabel(\"Count\")\n        out = REPORTS / \"error_hist.png\"\n        plt.tight_layout(); plt.savefig(out, bbox_inches=\"tight\", dpi=150)\n        plt.show()\n        print(\"Saved:\", out)\n    else:\n        print(\"predictions.csv missing required columns.\")\nelse:\n    print(\"predictions.csv not found.\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# --- Price Elasticity (log-log scatter) for a representative SKU-store ---\n# Try to load elasticity file; if missing, compute from features/sales.\nelas_fp = REPORTS / \"elasticity_by_sku.csv\"\nfeatures_fp = PROC / \"features.parquet\"\nsales_fp = PROC / \"sales_clean.parquet\"\n\ndef pick_pair(df):\n    key = df.groupby([\"product_id\",\"store_id\"])[\"units\"].sum().sort_values(ascending=False).head(1).index[0]\n    return key\n\nif elas_fp.exists():\n    elas = pd.read_csv(elas_fp)\n    print(\"Loaded elasticity_by_sku.csv with\", len(elas), \"rows\")\n    # If you want, you can plot distribution of elasticity values here.\nelif features_fp.exists():\n    feat = pd.read_parquet(features_fp)\n    have_price = \"price\" in feat.columns\n    if not have_price and sales_fp.exists():\n        sales = pd.read_parquet(sales_fp)[[\"product_id\",\"store_id\",\"date\",\"price\",\"units\"]]\n        feat = feat.merge(sales, on=[\"product_id\",\"store_id\",\"date\"], how=\"left\", suffixes=(\"\",\"_sales\"))\n        if \"price\" not in feat.columns and \"price_sales\" in feat.columns:\n            feat[\"price\"] = feat[\"price_sales\"]\n\n    if {\"product_id\",\"store_id\",\"date\",\"units\",\"price\"}.issubset(feat.columns):\n        pair = pick_pair(feat)\n        g = feat[(feat[\"product_id\"]==pair[0]) & (feat[\"store_id\"]==pair[1])].dropna(subset=[\"units\",\"price\"]).copy()\n        g = g[(g[\"units\"]>0) & (g[\"price\"]>0)]\n        if len(g) >= 20:\n            g[\"lu\"] = np.log(g[\"units\"])\n            g[\"lp\"] = np.log(g[\"price\"])\n            # OLS fit\n            X = np.c_[np.ones(len(g)), g[\"lp\"].to_numpy()]\n            y = g[\"lu\"].to_numpy()\n            b = np.linalg.lstsq(X, y, rcond=None)[0]  # intercept, slope\n            slope = b[1]\n            plt.figure(figsize=(6,5))\n            plt.scatter(g[\"lp\"], g[\"lu\"], alpha=0.5)\n            xline = np.linspace(g[\"lp\"].min(), g[\"lp\"].max(), 100)\n            yline = b[0] + slope * xline\n            plt.plot(xline, yline, linestyle=\"--\")\n            plt.title(f\"Log-Log Price vs Units (elasticity ≈ {slope:.2f})\\nproduct {pair[0]}, store {pair[1]}\")\n            plt.xlabel(\"log(price)\"); plt.ylabel(\"log(units)\")\n            out = REPORTS / \"elasticity_scatter.png\"\n            plt.savefig(out, bbox_inches=\"tight\", dpi=150)\n            plt.show()\n            print(\"Saved:\", out)\n        else:\n            print(\"Not enough observations for selected pair to estimate elasticity.\")\n    else:\n        print(\"Missing required columns to compute elasticity.\")\nelse:\n    print(\"No features.parquet or elasticity file found.\")\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}